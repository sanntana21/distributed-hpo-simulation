{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wRfO_Z_yqTAr"
      ],
      "authorship_tag": "ABX9TyNbGIYKyM+S5pFDSqaIxOqM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanntana21/distributed-hpo-simulation/blob/main/distributed_hpo_simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Big Data Analytics**\n",
        "\n",
        " - Álvaro Santana Sánchez\n",
        "\n",
        "---\n",
        "\n",
        "## Descripción del Proyecto\n",
        "\n",
        "Este proyecto tiene como objetivo la simulación del ajuste de hiperparámetros de un modelo de Machine Learning en un entorno Big Data distribuido. Aunque el entorno será simulado en un único notebook, se emulará el comportamiento de un sistema distribuido con múltiples workers.\n",
        "\n",
        "## Enfoque\n",
        "\n",
        "La optimización de los hiperparámetros se realizará utilizando un algoritmo evolutivo, una técnica inspirada en la evolución biológica. Este enfoque resulta adecuado para la búsqueda eficiente en espacios de soluciones complejos y no convexos, como es habitual en problemas de Machine Learning.\n",
        "\n",
        "## Principios del Algoritmo Evolutivo Aplicado\n",
        "\n",
        "- Individuo: Representa una combinación específica de hiperparámetros del modelo.\n",
        "\n",
        "- Población: Conjunto de individuos que serán evaluados en cada generación.\n",
        "\n",
        "- Función de fitness: Se define mediante la métrica F1-score, que permite evaluar el desempeño del modelo para cada configuración de hiperparámetros.\n",
        "\n",
        "- Mutación: Modificación aleatoria de uno o varios hiperparámetros de un individuo.\n",
        "\n",
        "- Cruzamiento: Combinación de dos individuos para generar nuevos candidatos.\n",
        "\n",
        "- Selección: Proceso por el cual se eligen los mejores individuos de una generación para formar parte de la siguiente.\n",
        "\n",
        "---\n",
        "\n",
        "## Arquitectura del Sistema Simulado\n",
        "Para simular el entorno Big Data, se considerará una arquitectura compuesta por un nodo Master y múltiples nodos Worker, representando un entorno distribuido:\n",
        "\n",
        "\n",
        "- Inicialización (Master): Se genera una población inicial de N individuos con combinaciones aleatorias de hiperparámetros.\n",
        "\n",
        "- Distribución (Master → Workers):\n",
        "El Master envía la población completa a cada uno de los Workers. Cada Worker tiene acceso a un subconjunto diferente del dataset (simulando datos distribuidos).\n",
        "\n",
        "- Evaluación Local (Worker):\n",
        "Cada individuo es evaluado localmente utilizando la vista del dataset asignado al Worker. La evaluación se realiza mediante el cálculo del F1-score.\n",
        "\n",
        "- Selección Local (Worker):\n",
        "Cada Worker selecciona los mejores individuos locales en función de su F1-score y envía sus resultados al Master.\n",
        "\n",
        "- Agregación Global (Master):\n",
        "El Master agrega los resultados recibidos de todos los Workers. Para cada individuo, se calcula la media de sus F1-score en todos los Workers. Luego, se ordenan los individuos según esta media para formar un ranking global.\n",
        "\n",
        "- Reproducción (Master):\n",
        "A partir del ranking global, el Master realiza operaciones de crossover y mutación sobre los mejores individuos para generar la nueva población.\n",
        "\n",
        "- Iteración:\n",
        "La nueva población se redistribuye a los Workers, y se repite el proceso desde el paso 3 durante un número determinado de generaciones.\n",
        "\n"
      ],
      "metadata": {
        "id": "se6QnxuSmYtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Inicialización del entorno pyspark"
      ],
      "metadata": {
        "id": "quILv8uHqDqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRTR-taxqDG1",
        "outputId": "64f1f22d-b361-45d2-f0b0-09794d186c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.memory\", \"1g\") \\\n",
        "    .config(\"spark.executor.memory\", \"1g\") \\\n",
        "    .appName(\"Spark SQL Lab\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "XKcqnCA8qBJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CYAN = \"\\033[96m\"\n",
        "GREEN = \"\\033[92m\"\n",
        "YELLOW = \"\\033[93m\"\n",
        "RESET = \"\\033[0m\"\n",
        "RED = \"\\033[91m\""
      ],
      "metadata": {
        "id": "9Dvc84wMzo_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de datos"
      ],
      "metadata": {
        "id": "-Oe8YCVbqoJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Cargar dataset de ejemplo\n",
        "data = load_breast_cancer()\n",
        "df_original = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df_original[\"label\"] = data.target\n",
        "\n",
        "# Convertir a Spark DataFrame\n",
        "df_spark = spark.createDataFrame(data=df_original)\n",
        "\n",
        "# Ver el esquema y una muestra\n",
        "df_spark.printSchema()\n",
        "df_spark.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei_v9VW9qrkO",
        "outputId": "8b8ac643-c3fb-42dc-bcdf-acbc5ce53113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- mean radius: double (nullable = true)\n",
            " |-- mean texture: double (nullable = true)\n",
            " |-- mean perimeter: double (nullable = true)\n",
            " |-- mean area: double (nullable = true)\n",
            " |-- mean smoothness: double (nullable = true)\n",
            " |-- mean compactness: double (nullable = true)\n",
            " |-- mean concavity: double (nullable = true)\n",
            " |-- mean concave points: double (nullable = true)\n",
            " |-- mean symmetry: double (nullable = true)\n",
            " |-- mean fractal dimension: double (nullable = true)\n",
            " |-- radius error: double (nullable = true)\n",
            " |-- texture error: double (nullable = true)\n",
            " |-- perimeter error: double (nullable = true)\n",
            " |-- area error: double (nullable = true)\n",
            " |-- smoothness error: double (nullable = true)\n",
            " |-- compactness error: double (nullable = true)\n",
            " |-- concavity error: double (nullable = true)\n",
            " |-- concave points error: double (nullable = true)\n",
            " |-- symmetry error: double (nullable = true)\n",
            " |-- fractal dimension error: double (nullable = true)\n",
            " |-- worst radius: double (nullable = true)\n",
            " |-- worst texture: double (nullable = true)\n",
            " |-- worst perimeter: double (nullable = true)\n",
            " |-- worst area: double (nullable = true)\n",
            " |-- worst smoothness: double (nullable = true)\n",
            " |-- worst compactness: double (nullable = true)\n",
            " |-- worst concavity: double (nullable = true)\n",
            " |-- worst concave points: double (nullable = true)\n",
            " |-- worst symmetry: double (nullable = true)\n",
            " |-- worst fractal dimension: double (nullable = true)\n",
            " |-- label: long (nullable = true)\n",
            "\n",
            "+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+-----+\n",
            "|mean radius|mean texture|mean perimeter|mean area|mean smoothness|mean compactness|mean concavity|mean concave points|mean symmetry|mean fractal dimension|radius error|texture error|perimeter error|area error|smoothness error|compactness error|concavity error|concave points error|symmetry error|fractal dimension error|worst radius|worst texture|worst perimeter|worst area|worst smoothness|worst compactness|worst concavity|worst concave points|worst symmetry|worst fractal dimension|label|\n",
            "+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+-----+\n",
            "|      17.99|       10.38|         122.8|   1001.0|         0.1184|          0.2776|        0.3001|             0.1471|       0.2419|               0.07871|       1.095|       0.9053|          8.589|     153.4|        0.006399|          0.04904|        0.05373|             0.01587|       0.03003|               0.006193|       25.38|        17.33|          184.6|    2019.0|          0.1622|           0.6656|         0.7119|              0.2654|        0.4601|                 0.1189|    0|\n",
            "|      20.57|       17.77|         132.9|   1326.0|        0.08474|         0.07864|        0.0869|            0.07017|       0.1812|               0.05667|      0.5435|       0.7339|          3.398|     74.08|        0.005225|          0.01308|         0.0186|              0.0134|       0.01389|               0.003532|       24.99|        23.41|          158.8|    1956.0|          0.1238|           0.1866|         0.2416|               0.186|         0.275|                0.08902|    0|\n",
            "|      19.69|       21.25|         130.0|   1203.0|         0.1096|          0.1599|        0.1974|             0.1279|       0.2069|               0.05999|      0.7456|       0.7869|          4.585|     94.03|         0.00615|          0.04006|        0.03832|             0.02058|        0.0225|               0.004571|       23.57|        25.53|          152.5|    1709.0|          0.1444|           0.4245|         0.4504|               0.243|        0.3613|                0.08758|    0|\n",
            "|      11.42|       20.38|         77.58|    386.1|         0.1425|          0.2839|        0.2414|             0.1052|       0.2597|               0.09744|      0.4956|        1.156|          3.445|     27.23|         0.00911|          0.07458|        0.05661|             0.01867|       0.05963|               0.009208|       14.91|         26.5|          98.87|     567.7|          0.2098|           0.8663|         0.6869|              0.2575|        0.6638|                  0.173|    0|\n",
            "|      20.29|       14.34|         135.1|   1297.0|         0.1003|          0.1328|         0.198|             0.1043|       0.1809|               0.05883|      0.7572|       0.7813|          5.438|     94.44|         0.01149|          0.02461|        0.05688|             0.01885|       0.01756|               0.005115|       22.54|        16.67|          152.2|    1575.0|          0.1374|            0.205|            0.4|              0.1625|        0.2364|                0.07678|    0|\n",
            "+-----------+------------+--------------+---------+---------------+----------------+--------------+-------------------+-------------+----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+------------+-------------+---------------+----------+----------------+-----------------+---------------+--------------------+--------------+-----------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simular particiones para cada uno de los workers\n",
        "NUM_WORKERS = 3\n",
        "splits = df_spark.randomSplit([1.0/NUM_WORKERS]*NUM_WORKERS, seed=130222)\n",
        "\n",
        "# Mostrar cuántos elementos tiene cada partición\n",
        "print(f\"Dataset original {(df_spark.count(), len(df_spark.columns))}\")\n",
        "for i, split in enumerate(splits):\n",
        "    print(f\"Worker {i+1} tiene {split.count()} registros.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtRdcNBUwSqj",
        "outputId": "7d0b860c-5242-489c-dbee-8ec97a26dfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset original (569, 31)\n",
            "Worker 1 tiene 188 registros.\n",
            "Worker 2 tiene 178 registros.\n",
            "Worker 3 tiene 203 registros.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ajuste de hiperparámetros"
      ],
      "metadata": {
        "id": "FmViyyYZsppT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "#Esta parametro permite limitar el espacio de busqueda una maya de parametros concreta\n",
        "HIPERPARAMETROS_DISPONIBLES = {\n",
        "    \"n_estimators\": [50, 100, 150],\n",
        "    \"max_depth\": [3, 5, 10],\n",
        "    \"min_samples_split\": [2, 5, 10]\n",
        "}\n",
        "\n",
        "class Individuo:\n",
        "  \"\"\"\n",
        "  Esta clase se utiliza para definir un individuo, el cúal estará formado por un\n",
        "  conjunto de hiperpámetro.\n",
        "\n",
        "  Si no se definen unos hiperparámetros de entrada, se genera aleatoriamente el\n",
        "  individuo.\n",
        "  \"\"\"\n",
        "  def __init__(self, genes : dict =None):\n",
        "      self.genes = genes or {k: random.choice(v) for k, v in HIPERPARAMETROS_DISPONIBLES.items()}\n",
        "      self.fitness = None\n",
        "\n",
        "  def mutate(self, verbose : bool = False):\n",
        "    \"\"\"\n",
        "    Mutar uno de los hiperparámetros aleatoriamente\n",
        "    \"\"\"\n",
        "    param_to_mutate = random.choice(list(HIPERPARAMETROS_DISPONIBLES.keys()))\n",
        "    antes = self.genes[param_to_mutate]\n",
        "    if verbose:\n",
        "      print(f\"{YELLOW} Individuo mutando atributo {param_to_mutate} {RESET}\")\n",
        "    self.genes[param_to_mutate] = random.choice([h for h in HIPERPARAMETROS_DISPONIBLES[param_to_mutate] if h != antes])\n",
        "    if verbose:\n",
        "      print(f\"Antes {antes}, despues {self.genes[param_to_mutate]}\")\n",
        "\n",
        "  def _set_fitness(self, fitness : float):\n",
        "    self.fitness = fitness\n",
        "\n",
        "  def __str__(self):\n",
        "    # Texto de genes\n",
        "    genes_str = f\"{CYAN}{self.genes}{RESET}\"\n",
        "\n",
        "    # Texto de fitness\n",
        "    if self.fitness is None:\n",
        "      fitness_str = f\"{YELLOW}Pendiente{RESET}\"\n",
        "    else:\n",
        "      fitness_str = f\"{GREEN}{self.fitness:.4f}{RESET}\"\n",
        "\n",
        "    return f\"\\n\\tGenes {genes_str}, \\n\\tFitness: {fitness_str}\"\n"
      ],
      "metadata": {
        "id": "KG9-51NbtlFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "def calcular_fitness_individuo(data : list, individuo : Individuo = None, model = RandomForestClassifier):\n",
        "    \"\"\"\n",
        "    Esta función calcula el fitness de un determinado individuo, para ello\n",
        "    ajusta\n",
        "    \"\"\"\n",
        "    if not individuo:\n",
        "      raise ValueError(\"Debe seleccionar un individuo\")\n",
        "\n",
        "    if not model:\n",
        "      raise ValueError(\"Debe seleccionar un modelo\")\n",
        "\n",
        "    #Separamos datos de etiquetas\n",
        "    X = np.array(data)[:,:-1]\n",
        "    y = np.array(data)[:, -1]\n",
        "\n",
        "    # Realizamos separación de datos en train y test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=130222)\n",
        "\n",
        "    # Crear y entrenar modelo con los hiperparámetros del individuo\n",
        "    clf = model(**individuo.genes)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    fitness = f1_score(y_test, y_pred)\n",
        "\n",
        "    return fitness\n",
        "\n",
        "# Simular evaluar un individuo con un RDD por worker\n",
        "def evaluar_individuo_en_worker(individuo, df_worker):\n",
        "    return df_worker.rdd.mapPartitions(\n",
        "        lambda iter_rows: [calcular_fitness_individuo(list(iter_rows), individuo)]\n",
        "    ).collect()[0]"
      ],
      "metadata": {
        "id": "hgBPnx6Qr6-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Población inicial\n",
        "\n",
        "Se genera de manera aleatoria una población inicial"
      ],
      "metadata": {
        "id": "1HNWj6Xz7BRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Definicion de la poblacion inicial\n",
        "TOTAL_INDIVIDUOS = 9\n",
        "INDIVIDUOS_POR_WORKER = round(TOTAL_INDIVIDUOS / NUM_WORKERS)\n",
        "POBLACION_ACTUAL = [Individuo() for _ in range(TOTAL_INDIVIDUOS)]"
      ],
      "metadata": {
        "id": "MDfE0yk_s1bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Primera iteración\n",
        "\n",
        "Se realiza una primera iteración para conjunto de workers e individuos y\n",
        "se calcula un ranking de los mejores individuos de la iteración"
      ],
      "metadata": {
        "id": "-qmZZUzJ7I1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, split in enumerate(splits):\n",
        "    print(f\"\\n {RED} Worker {i+1} {RESET}\")\n",
        "\n",
        "    rows = split.toPandas().values.tolist()\n",
        "\n",
        "    start = i * INDIVIDUOS_POR_WORKER\n",
        "    end = min(start + INDIVIDUOS_POR_WORKER, TOTAL_INDIVIDUOS) if i < NUM_WORKERS - 1 else TOTAL_INDIVIDUOS\n",
        "    individuos_asignados = POBLACION_ACTUAL[start:end]\n",
        "\n",
        "    for idx, individuo in enumerate(POBLACION_ACTUAL[start:end]):\n",
        "        f1 = calcular_fitness_individuo(rows, individuo)\n",
        "        individuo._set_fitness(f1)\n",
        "        print(f\"Worker {i+1}: Individuo : {individuo}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBxQh9Xd3Gmg",
        "outputId": "be960f60-234f-4c6b-f908-9c4eca80c585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \u001b[91m Worker 1 \u001b[0m\n",
            "Worker 1: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Worker 1: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Worker 1: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "\n",
            " \u001b[91m Worker 2 \u001b[0m\n",
            "Worker 2: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9610\u001b[0m\n",
            "Worker 2: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 10}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9610\u001b[0m\n",
            "Worker 2: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 10}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9610\u001b[0m\n",
            "\n",
            " \u001b[91m Worker 3 \u001b[0m\n",
            "Worker 3: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9610\u001b[0m\n",
            "Worker 3: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 3, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9487\u001b[0m\n",
            "Worker 3: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selección\n",
        "\n",
        "Mediante la selección nos quedamos con el top de mejores individuos."
      ],
      "metadata": {
        "id": "4ef7qDT-70lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obtener_mejores_individuos(individuos, top_k):\n",
        "  \"\"\"\n",
        "  Esta función selecciona los mejores individuos de una población\n",
        "  \"\"\"\n",
        "  return sorted(individuos, key=lambda ind: ind.fitness, reverse=True)[:top_k]\n",
        "\n",
        "\n",
        "print(f\"{RED}RANKING ACTUAL{RESET}\")\n",
        "TOP_K = 5\n",
        "if TOP_K > TOTAL_INDIVIDUOS:\n",
        "  raise ValueError(\"Disminuye el top o aumenta el numero de individuos\")\n",
        "POBLACION_ACTUAL = obtener_mejores_individuos(POBLACION_ACTUAL, TOP_K)\n",
        "for a in POBLACION_ACTUAL:\n",
        "  print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuixgIdd3yb_",
        "outputId": "d4e3f3e0-95f2-4358-ed0a-2bd1607104ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91mRANKING ACTUAL\u001b[0m\n",
            "\n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "\n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "\n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cruze\n",
        "\n",
        "Combinamos los mejores individuos entre sí."
      ],
      "metadata": {
        "id": "cYJFZ6li77sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cruzar_genes(padre1 : Individuo, padre2 : Individuo):\n",
        "    \"\"\"Cruce uniforme entre dos individuos de la población\"\"\"\n",
        "    nuevo_genes = {}\n",
        "    for k in HIPERPARAMETROS_DISPONIBLES.keys():\n",
        "        nuevo_genes[k] = random.choice([padre1.genes[k], padre2.genes[k]])\n",
        "    return Individuo(genes=nuevo_genes)\n",
        "\n",
        "def generar_nueva_poblacion(padres : list[Individuo],\n",
        "                            prob_mutacion : float = 0.3,\n",
        "                            tam_nueva_poblacion : int = TOTAL_INDIVIDUOS,\n",
        "                            verbose : bool = False\n",
        "                            ):\n",
        "  \"\"\"\n",
        "  Dada una población se realiza la creación de una nueva mediante\n",
        "  \"\"\"\n",
        "  nueva_poblacion = []\n",
        "  while len(nueva_poblacion) < tam_nueva_poblacion:\n",
        "    padre1, padre2 = random.sample(padres, 2)\n",
        "    if verbose:\n",
        "      print(\"Padre 1\", padre1)\n",
        "      print(\"Padre 2\", padre2)\n",
        "    hijo = cruzar_genes(padre1, padre2)\n",
        "    if verbose:\n",
        "      print(\"Generado hijo\",hijo)\n",
        "\n",
        "    # Mutación aleatoria con cierta probabilidad\n",
        "    if random.random() < prob_mutacion:\n",
        "      hijo.mutate(verbose=verbose)\n",
        "\n",
        "    nueva_poblacion.append(hijo)\n",
        "\n",
        "    if verbose:\n",
        "      print(\"-\"*50)\n",
        "\n",
        "  return nueva_poblacion\n",
        "\n",
        "NUEVA_POBLACION = generar_nueva_poblacion(POBLACION_ACTUAL,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEcmdpos6k-d",
        "outputId": "8ba17880-f0ce-4c44-bfe9-8a6fa6f62a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padre 1 \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Padre 2 \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Generado hijo \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[93mPendiente\u001b[0m\n",
            "--------------------------------------------------\n",
            "Padre 1 \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Padre 2 \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Generado hijo \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[93mPendiente\u001b[0m\n",
            "--------------------------------------------------\n",
            "Padre 1 \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Padre 2 \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Generado hijo \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[93mPendiente\u001b[0m\n",
            "--------------------------------------------------\n",
            "Padre 1 \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Padre 2 \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Generado hijo \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[93mPendiente\u001b[0m\n",
            "\u001b[93m Individuo mutando atributo min_samples_split \u001b[0m\n",
            "Antes 2, despues 5\n",
            "--------------------------------------------------\n",
            "Padre 1 \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Padre 2 \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Generado hijo \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[93mPendiente\u001b[0m\n",
            "--------------------------------------------------\n",
            "Padre 1 \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Padre 2 \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Generado hijo \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[93mPendiente\u001b[0m\n",
            "\u001b[93m Individuo mutando atributo n_estimators \u001b[0m\n",
            "Antes 150, despues 50\n",
            "--------------------------------------------------\n",
            "Padre 1 \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Padre 2 \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Generado hijo \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[93mPendiente\u001b[0m\n",
            "--------------------------------------------------\n",
            "Padre 1 \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Padre 2 \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Generado hijo \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[93mPendiente\u001b[0m\n",
            "\u001b[93m Individuo mutando atributo min_samples_split \u001b[0m\n",
            "Antes 5, despues 10\n",
            "--------------------------------------------------\n",
            "Padre 1 \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Padre 2 \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Generado hijo \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[93mPendiente\u001b[0m\n",
            "\u001b[93m Individuo mutando atributo min_samples_split \u001b[0m\n",
            "Antes 5, despues 2\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Segunda iteración\n",
        "\n",
        "Se realiza una nueva iteración utilizando los valores creados por el cruce."
      ],
      "metadata": {
        "id": "rWci4L0OBJcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, split in enumerate(splits):\n",
        "    print(f\"\\n {RED} Worker {i+1} {RESET}\")\n",
        "\n",
        "    start = i * INDIVIDUOS_POR_WORKER\n",
        "    end = min(start + INDIVIDUOS_POR_WORKER, TOTAL_INDIVIDUOS) if i < NUM_WORKERS - 1 else TOTAL_INDIVIDUOS\n",
        "    individuos_asignados = NUEVA_POBLACION[start:end]\n",
        "\n",
        "    for idx, individuo in enumerate(NUEVA_POBLACION[start:end]):\n",
        "        f1 = calcular_fitness_individuo(rows, individuo)\n",
        "        individuo._set_fitness(f1)\n",
        "        print(f\"Worker {i+1}: Individuo : {individuo}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X8a1-w6BFwk",
        "outputId": "51d5426a-8140-4948-b267-040b8a015dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \u001b[91m Worker 1 \u001b[0m\n",
            "Worker 1: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m1.0000\u001b[0m\n",
            "Worker 1: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Worker 1: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9610\u001b[0m\n",
            "\n",
            " \u001b[91m Worker 2 \u001b[0m\n",
            "Worker 2: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9737\u001b[0m\n",
            "Worker 2: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Worker 2: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9610\u001b[0m\n",
            "\n",
            " \u001b[91m Worker 3 \u001b[0m\n",
            "Worker 3: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "Worker 3: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 10}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9737\u001b[0m\n",
            "Worker 3: Individuo : \n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9600\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mejores individuos segunda poblacion\n",
        "print(f\"{RED}RANKING ACTUAL{RESET}\")\n",
        "NUEVA_POBLACION_RANKING = obtener_mejores_individuos(NUEVA_POBLACION, TOP_K)\n",
        "for a in NUEVA_POBLACION_RANKING:\n",
        "  print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G841J3OHBhFT",
        "outputId": "0b98faea-7988-4c8b-fe0a-ba96ac75fef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91mRANKING ACTUAL\u001b[0m\n",
            "\n",
            "\tGenes \u001b[96m{'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m1.0000\u001b[0m\n",
            "\n",
            "\tGenes \u001b[96m{'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "\n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 2}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "\n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9867\u001b[0m\n",
            "\n",
            "\tGenes \u001b[96m{'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 5}\u001b[0m, \n",
            "\tFitness: \u001b[92m0.9737\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop\n",
        "\n",
        "Se detiene el contexto de pyspark y se finaliza"
      ],
      "metadata": {
        "id": "wRfO_Z_yqTAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()"
      ],
      "metadata": {
        "id": "eRturl6yqYVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}